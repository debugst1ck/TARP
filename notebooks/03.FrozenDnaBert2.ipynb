{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tarp.model.backbone.untrained.lstm import LstmEncoder\n",
    "from tarp.model.backbone.untrained.hyena import HyenaEncoder\n",
    "from tarp.model.finetuning.classification import ClassificationModel\n",
    "\n",
    "from tarp.services.datasets.classification.multilabel import MultiLabelClassificationDataset\n",
    "from tarp.services.tokenizers.pretrained.dnabert import Dnabert2Tokenizer\n",
    "from tarp.services.datasource.sequence import TabularSequenceSource, CombinationSource, FastaSliceSource\n",
    "\n",
    "\n",
    "from tarp.services.preprocessing.augumentation import (\n",
    "    CombinationTechnique,\n",
    "    RandomMutation,\n",
    "    InsertionDeletion,\n",
    "    ReverseComplement,\n",
    ")\n",
    "\n",
    "from tarp.services.datasets.metric.triplet import MultilabelOfflineTripletDataset\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = (\n",
    "    pl.read_csv(Path(\"../temp/data/processed/labels.csv\")).to_series().to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiLabelClassificationDataset(\n",
    "    CombinationSource(\n",
    "        [\n",
    "            TabularSequenceSource(\n",
    "                source=Path(\"../temp/data/processed/card_amr.parquet\")\n",
    "            ),\n",
    "            FastaSliceSource(\n",
    "                directory=Path(\"../temp/data/external/sequences\"),\n",
    "                metadata=Path(\"../temp/data/processed/non_amr_genes_10000.parquet\"),\n",
    "                key_column=\"genomic_nucleotide_accession.version\",\n",
    "                start_column=\"start_position_on_the_genomic_accession\",\n",
    "                end_column=\"end_position_on_the_genomic_accession\",\n",
    "                orientation_column=\"orientation\",\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    Dnabert2Tokenizer(),\n",
    "    sequence_column=\"sequence\",\n",
    "    label_columns=label_columns,\n",
    "    maximum_sequence_length=512,\n",
    "    augumentation=CombinationTechnique(\n",
    "        [\n",
    "            RandomMutation(),\n",
    "            InsertionDeletion(),\n",
    "            ReverseComplement(0.5),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "metric_dataset = MultilabelOfflineTripletDataset(\n",
    "    base_dataset=dataset, label_cache=\"../temp/data/interim/labels_cache.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tarp.config import Dnabert2Config\n",
    "from tarp.model.backbone.pretrained.dnabert2 import FrozenDnabert2Encoder\n",
    "\n",
    "encoder = FrozenDnabert2Encoder(Dnabert2Config().hidden_dimension)\n",
    "\n",
    "classification_model = ClassificationModel(\n",
    "    encoder=encoder,\n",
    "    number_of_classes=len(label_columns),\n",
    ")\n",
    "\n",
    "classification_model.load_state_dict(\n",
    "    torch.load(\"../temp/checkpoints/FrozenDnabert2Encoder_20251014_132302.pt\")\n",
    ")\n",
    "\n",
    "# Get the encoder part of the model\n",
    "encoder: FrozenDnabert2Encoder = classification_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the dataset to get the embeddings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Preallocate numpy array for all embeddings\n",
    "num_samples = len(dataset)\n",
    "batch_size = 32\n",
    "embedding_dim = encoder.encoding_size  # Output dimension of encoder.encode\n",
    "embeddings = np.empty((num_samples, embedding_dim), dtype=np.float32)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(DEVICE)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "start_idx = 0\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch[\"sequence\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        batch_embeddings = encoder.encode(input_ids, attention_mask)\n",
    "        batch_size_actual = batch_embeddings.shape[0]\n",
    "        embeddings[start_idx:start_idx + batch_size_actual] = batch_embeddings.cpu().numpy()\n",
    "        start_idx += batch_size_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the embeddings\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_embeddings = embeddings[:train_size]\n",
    "test_embeddings = embeddings[train_size:]\n",
    "\n",
    "print(\"Train embeddings shape:\", train_embeddings.shape)\n",
    "print(\"Test embeddings shape:\", test_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN search\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "\n",
    "knn.fit(train_embeddings, [\n",
    "    dataset[i]['labels'].numpy() for i in range(train_size)\n",
    "])\n",
    "\n",
    "# Classify test set\n",
    "predictions = knn.predict(test_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    [dataset[i + train_size]['labels'].numpy() for i in range(len(test_embeddings))],\n",
    "    predictions,\n",
    "    zero_division=0,\n",
    "    target_names=label_columns\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Run t-SNE on the embeddings\n",
    "tsne = TSNE(n_components=2, random_state=102, perplexity=30)\n",
    "train_embeddings_2d = tsne.fit_transform(train_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7696bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Collect labels for the training split\n",
    "labels = []\n",
    "dataloader_labels = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for i, batch in enumerate(dataloader_labels):\n",
    "    if i * 32 >= train_size:  # stop after train split\n",
    "        break\n",
    "    labels.append(batch[\"labels\"].numpy())\n",
    "\n",
    "train_labels = np.vstack(labels)[:train_size]  # shape (N, num_labels)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "\n",
    "# Convert multilabel â†’ single label for visualization\n",
    "train_labels_simple = train_labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5769465",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    x=train_embeddings_2d[:, 0],\n",
    "    y=train_embeddings_2d[:, 1],\n",
    "    color=[label_columns[i] for i in train_labels_simple],\n",
    "    title=\"t-SNE visualization of Frozen DNABERT-2 embeddings\",\n",
    "    labels={\"x\": \"t-SNE dim 1\", \"y\": \"t-SNE dim 2\", \"color\": \"Gene family\"},\n",
    "    opacity=0.7,\n",
    ")\n",
    "# Square figure\n",
    "fig.update_layout(width=1024, height=768)\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
